---
layout: none
category: "Research"
within_category_ix: 50
title:  "Diffusion sampling in 4 steps"
---

<figure class="table-fig center-fig article-fig">
  <table>
    <tbody>
      <tr>
        <td>
          <a href="/assets/machine-learning/few-step/youmu.png">
            <img src="/assets/machine-learning/few-step/youmu.png" width="256px" height="256px" loading="lazy">
          </a>
        </td>
        <td>
          <a href="/assets/machine-learning/few-step/fairy.png">
            <img src="/assets/machine-learning/few-step/fairy.png" width="256px" height="256px" loading="lazy">
          </a>
        </td>
      </tr>
    </tbody>
  </table>
  <figcaption>4-step samples; hand-picked sigmas (6.1080, 1.5968, 0.4765, 0.1072)</figcaption>
</figure>

<p>
  Inferencing from diffusion models is slow on Mac, so I was keen to cut down the number of steps required for sampling.
</p>
<p>
  We can be tactical about which sigmas we denoise. We get good facial details by including a step at sigma ~0.1, and we can even <a href="https://github.com/crowsonkb/k-diffusion/pull/23">end our denoising schedule there</a>, rather than going all the way down to stable-diffusion's <a href="https://gist.github.com/Birch-san/6cd1574e51871a5e2b88d59f0f3d4fd3">minimum of 0.0292</a>.<br>Raising sigma_min like this cuts a lot of low sigma steps out of our schedule, which doesn't seem to harm the image much; an 8-step schedule ending at sigma 0.0936 can often make good images with Heun sampler.
</p>
<p>I managed some 4-step samples as well; hand-picked sigmas were able to get better results than the Karras schedule, by optimizing for the timesteps at which the Unet proved most effective.<br>
I wonder whether the yield could be made more consistent by training an <a href="https://arxiv.org/abs/2211.01324">ensemble of expert denoisers</a>, specialized at each of those 4 sigmas!
</p>
<p>
  The pursuit for few-step sampling also included a collaboration with Katherine Crowson â€” she suggested to try modifying the DPM-Solver++(2M) sampler to begin with a DPM-Solver++(2S) step, to warm up the linear multistep. It <a href="https://github.com/crowsonkb/k-diffusion/issues/43#issuecomment-1309571364">seemed to help</a>!
</p>
<ul>
  <li><a href="https://twitter.com/Birchlabs/status/1564792349221330944">7-step Heun/Karras sample by elevating <code>sigma_min</code></a></li>
  <li><a href="https://twitter.com/Birchlabs/status/1564792349221330944">5-step DPM-Solver++(2M)/Karras sample by bending rho and limiting <code>sigma_{max,min}</code></a></li>
  <li><a href="https://twitter.com/Birchlabs/status/1614794909717876736">Hi-res 5-step DPM-Solver++(2M)/Karras sample by bending rho and limiting <code>sigma_{max,min}</code></a></li>
  <li><a href="https://twitter.com/Birchlabs/status/1597393825261301760">4-step DPM-Solver++(2M) sample via hand-picked sigma schedule</a></li>
  <li><a href="https://github.com/crowsonkb/k-diffusion/issues/43#issuecomment-1309562742">Implementation: DPM-Solver++(2M) with 2S warmup</a></li>
</ul>