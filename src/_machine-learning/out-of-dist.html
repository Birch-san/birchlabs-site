---
layout: none
category: "Research"
within_category_ix: 60
title:  "Out-of-distribution generation"
---

<figure class="table-fig center-fig article-fig">
  <table>
    <tbody>
      <tr>
        <td>
          <a href="/assets/machine-learning/out-of-dist/smaller-usual.png">
            <img src="/assets/machine-learning/out-of-dist/smaller-usual.png" width="200px" height="200px" loading="lazy">
          </a>
        </td>
        <td>
          <a href="/assets/machine-learning/out-of-dist/smaller-quantile.png">
            <img src="/assets/machine-learning/out-of-dist/smaller-quantile.png" width="200px" height="200px" loading="lazy">
          </a>
        </td>
      </tr>
    </tbody>
  </table>
  <figcaption>Fixing a smaller-than-usual image by subtracting representative attention scores from denominator</figcaption>
</figure>

<p>Stable-diffusion is poor at generating images smaller or larger than those in its training distribution. I wondered how much of that could be attributed to the <a href="https://github.com/lllyasviel/ControlNet/discussions/12">impact of an unexpected key length</a> on self-attention's softmax averaging.</p>
<p>My hypothesis was that if we could adjust the magnitude of the softmax denominator to be in-distribution: we may be able to correctly generate images at out-of-distribution sizes without retraining.</p>
<p>If our image is too small: our self-attention key length will be small, our softmax denominator will be small, our attention probabilities will be large. Vice-versa for "too large".</p>
<p>Can we bring a larger-than-usual image into distribution by computing softmax denominator from a subset of attention scores?<br>Can we bring a smaller-than-usual image into distribution by extrapolating "more attention scores" in our denominator by sampling from those available?</p>
<p>This was a research collaboration I pursued with Kharr and tpapp157 at <a href="https://www.eleuther.ai/">EleutherAI</a>. I am currently writing up our findings, to publish as an EleutherAI blog post.</p>
<ul>
  <li><a href="https://twitter.com/Birchlabs/status/1642680652377075712">Fixing a smaller-than-usual image by subtracting representative attention scores from denominator</a></li>
  <li><a href="https://twitter.com/Birchlabs/status/1643020670912045057">Fixing a larger-than-usual image by computing denominator from topk attention scores</a></li>
  <li><a href="https://discord.com/channels/729741769192767510/747850033994662000/1094279577569857707">(Attempting to fix) a larger-than-usual image by ToMe token-merging key and value to in-distribution sequence lengths</a></li>
</ul>

<figure class="table-fig center-fig article-fig">
  <table>
    <tbody>
      <tr>
        <td>
          <a href="/assets/machine-learning/out-of-dist/larger-usual.png">
            <img src="/assets/machine-learning/out-of-dist/larger-usual.png" width="256px" height="256px" loading="lazy">
          </a>
        </td>
        <td>
          <a href="/assets/machine-learning/out-of-dist/larger-topk.png">
            <img src="/assets/machine-learning/out-of-dist/larger-topk.png" width="256px" height="256px" loading="lazy">
          </a>
        </td>
      </tr>
    </tbody>
  </table>
  <figcaption>Fixing a larger-than-usual image by computing denominator from topk attention scores</figcaption>
</figure>